### 中文解释：
题目要求我们对表格中的数据（包括特征数据和标签数据）做Z-Score标准化，也叫Z-Score归一化。Z-Score标准化的公式如下：

\[
z = \frac{x - \mu}{\sigma}
\]

其中：
- \(x\) 是原数据
- \(\mu\) 是该列的均值
- \(\sigma\) 是该列的标准差

你需要对三列数据分别做Z-Score标准化：sq ft（平方英尺），no of bedrooms（卧室数），price（价格）。

---

### Python代码（直接运行可以得到标准化后的结果）：

```python
import numpy as np
import pandas as pd

# 原始数据
data = {
    "sq_ft": [500, 800, 1000, 1200, 1600, 1800, 2000, 2200, 2400, 2600],
    "bedrooms": [1, 1, 2, 2, 3, 3, 4, 4, 4, 5],
    "price": [
        500000, 600000, 700000, 800000, 900000, 
        1000000, 1100000, 1200000, 1300000, 1400000
    ]
}

# 转为DataFrame
df = pd.DataFrame(data)

# Z-Score 标准化
df_zscore = (df - df.mean()) / df.std()

print(df_zscore)
```

---

### 英文回答（Z-Score Normalized Data Example for the 3 columns）:

| Sample | sq ft (z-score) | no of bedrooms (z-score) | price (z-score) |
|--------|-----------------|-------------------------|-----------------|
| 1      | (500-1510)/712.96   | (1-2.9)/1.37               | (500000-950000)/303315.02 |
| ...    | ...             | ...                     | ...             |

(完整数值请使用上面的Python代码获得！)

**Explanation:**  
For each value, subtract the mean of the column, then divide by the standard deviation of that column.

---

如果你需要结果表格可以把我上面的Python代码运行一下，然后结果复制到这里。 有疑问可以随时问我！







这个图展示的是神经网络中某一层（第l层）的激活值 \(a^{[l]}\)。每一个圆表示神经元，右边的\(a^{[l]}_i\)表示第l层中第i个神经元的激活值。比如\(a^{[l]}_1\)表示第1个神经元的激活，\(a^{[l]}_2\)表示第2个神经元，以此类推到\(a^{[l]}_{10}\)。

**解释：**
- 这是神经网络常用的表达方式，用来表示每一层的神经元输出（激活值）。
- 通常 \(a^{[l]}\) 是一列向量，每个分量代表一个神经元的激活。
- l 表示第几层，i 表示这一层的第几个神经元。

**英文回答：**

This diagram shows the activations of neurons in the l-th layer of a neural network. Each orange circle represents a neuron, and \( a^{[l]}_i \) is the activation of the i-th neuron in layer l. For example, \( a^{[l]}_1 \) is the activation of the first neuron, \( a^{[l]}_2 \) is the activation of the second neuron, and so on up to \( a^{[l]}_{10} \).

In short:  
Each \( a^{[l]}_i \) represents the output (activation) of the i-th neuron in the l-th layer of the neural network.







我们来看一下题目的要求：

### 中文解释：
1. 第一个问题是在这个例子中，第3个和第15个样本，对应哪几个神经元的激活被“归零”了（也就是被drop out了）。你需要找到mask的第3行和第15行，看那些位置是0，就是被归零的神经元序号（注意索引从0开始）。
2. 第二个问题是：每个样本，所有激活的乘法因子是多少？意思是dropout后每个神经元要除以（1-p），p是drop概率。

---

### 英文作答：

**1) In this example, for sample number 3 and 15, which neuron(s) are zeroed out?**

- For sample number 3 (index 2):  
  The mask row is: `[0 0 0 0 0 0 0 0 0 0]`.  
  All neurons (indices 0 to 9) are zeroed out.

- For sample number 15 (index 14):  
  The mask row is: `[0 0 0 0 0 0 0 0 1 0]`.  
  All neurons except neuron 8 are zeroed out.  
  Zeroed neurons are: 0, 1, 2, 3, 4, 5, 6, 7, and 9.

---

**2) For each sample, what is the multiplication factor for all activations?**

Since the dropout probability is 0.8, the retaining probability is 0.2. The multiplication factor for all activations (during training) is:  

`1 / (1 - 0.8) = 1 / 0.2 = 5`

---

#### 总结答案：

**Your Answer:**

1. For sample number 3, all neurons (0-9) are zeroed out.  
   For sample number 15, neurons 0, 1, 2, 3, 4, 5, 6, 7, and 9 are zeroed out.

2. The multiplication factor for all activations for each sample is 5.







### 中文解释

1）题目问在这个例子中，编号为3 和 15 的样本，各自有哪几个神经元被置零（就是dropout掉了）？  
2）每个样本，所有激活值的缩放因子（multiplication factor）是多少？

我们要看 mask\[l\] 这个二进制矩阵。每一行是一个样本（第3行和第15行），每一列表示一个神经元，0 就是被“dropout”；1 就是保留。

dropout概率p=0.8，所以只有20%的神经元被保留，为了保证期望一致，保留的要除以0.2，相当于乘以 1/0.2 = 5。

---

### 英文回答

#### 1) For sample number 3 and 15, which neuron(s) are zeroed out?

- **Sample number 3**: (The 3rd row, note Python is zero-indexed, so the 3rd sample is row index 2)  
Row: `[0 0 0 0 0 0 0 0 0 0]`  
All neurons (1 to 10) are zeroed out.

- **Sample number 15**: (The 15th row, row index 14)  
Row: `[0 0 0 0 0 0 0 0 1 0]`  
Neurons 1 to 8 and 10 are zeroed out. Only neuron 9 is kept.

**Answer:**  
Sample 3: Neurons 1, 2, 3, 4, 5, 6, 7, 8, 9, and 10 are zeroed out.  
Sample 15: Neurons 1, 2, 3, 4, 5, 6, 7, 8, and 10 are zeroed out.

---

#### 2) For each sample, what is the multiplication factor for all activations?

Since the drop probability is 0.8, the keep probability is 0.2, so the scaling factor is **1/0.2 = 5**.

**Answer:**  
The multiplication factor for all activations is 5.







